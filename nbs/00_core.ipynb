{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08c3638c62bbd0b",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Dockerfile generation, image building, container running, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c780e8479786f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e7b8541e15b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b52454175ab4d4",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nimport os, re, json, subprocess\nfrom pathlib import Path\nfrom functools import partial\nfrom fastcore.all import listify, joins, is_listy, L, patch, true, concat"
  },
  {
   "cell_type": "markdown",
   "id": "cd07b06a5bbb370e",
   "metadata": {},
   "source": [
    "## Dockerfile Instructions\n",
    "\n",
    "`instr` creates a Dockerfile instruction string from a keyword and value. Factory functions (`from_`, `run_`, `cmd_`, etc.) wrap `instr` for each Dockerfile keyword, handling formatting details like tag joining, JSON exec form, and multi-command chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112779e5025a332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _instr(kw, v): return f'{kw} {v}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f163c08799cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _instr('RUN', 'echo hello') == 'RUN echo hello'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46122054b4e08ac8",
   "metadata": {},
   "source": [
    "### Instruction factory functions\n",
    "\n",
    "Each function maps to a Dockerfile keyword with a trailing `_` to avoid clashing with Python builtins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14b9bf7a117b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _from(image:str, tag:str=None, as_:str=None) -> str:\n",
    "    'From instruction -- base image with optional tag and alias'\n",
    "    return _instr('FROM', '%s%s%s' % (image, ':%s' % tag if tag else '', ' AS %s' % as_ if as_ else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3424c341872eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _from('python', '3.11') == 'FROM python:3.11'\n",
    "assert _from('ubuntu', as_='builder') == 'FROM ubuntu AS builder'\n",
    "assert _from('alpine') == 'FROM alpine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749a2a4ac1b4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _run(cmd: list | str):\n",
    "    'RUN instruction -- execute command(s) in shell'\n",
    "    return _instr('RUN', joins(' && ', listify(cmd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92098cdbcdb6df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _run('apt-get update') == 'RUN apt-get update'\n",
    "r = _run(['apt-get update', 'apt-get install -y curl'])\n",
    "assert 'apt-get update && ' in r\n",
    "assert 'apt-get install -y curl' in r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r49lgjh5y2i",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _apt_install(*pkgs, y=False):\n",
    "    'RUN apt-get update && apt-get install packages'\n",
    "    flag = '-y ' if y else ''\n",
    "    return _run(['apt-get update', f'apt-get install {flag}{\" \".join(pkgs)}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gfw9dekfs66",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _apt_install('curl', 'wget', y=True) == 'RUN apt-get update && apt-get install -y curl wget'\n",
    "assert _apt_install('git') == 'RUN apt-get update && apt-get install git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7840b601f4f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _cmd(cmd: list | str):\n",
    "    \"CMD instruction -- default command for container\"\n",
    "    return _instr('CMD', json.dumps(cmd) if is_listy(cmd) else cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc05ab86a87f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _cmd(['python', 'app.py']) == 'CMD [\"python\", \"app.py\"]'\n",
    "assert _cmd('echo hello') == 'CMD echo hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6c641b8c5eb53",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef _copy(src:str, dst:str, from_:str=None, link=False):\n    'COPY instruction -- copy files into image'\n    flags = f'{\"--link \" if link else \"\"}{\"--from=%s \" % from_ if from_ else \"\"}'\n    return _instr('COPY', f'{flags}{src} {dst}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16a4bba67819f9",
   "metadata": {},
   "outputs": [],
   "source": "assert _copy('.', '/app') == 'COPY . /app'\nassert _copy('/build/out', '/app', from_='builder') == 'COPY --from=builder /build/out /app'\nassert _copy('app/', '.', link=True) == 'COPY --link app/ .'\nassert _copy('/app', '/app', from_='builder', link=True) == 'COPY --link --from=builder /app /app'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae4a4f4f2e1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _add(src:str, dst:str):\n",
    "    'ADD instruction -- copy files/URLs into image'\n",
    "    return _instr('ADD', f'{src} {dst}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fa65a053082d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _workdir(path):\n",
    "    'WORKDIR instruction -- set working directory'\n",
    "    return _instr('WORKDIR', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33777d8f7672c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _workdir('/app') == 'WORKDIR /app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5673990f345da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _env(k, v=None):\n",
    "    'ENV instruction -- set environment variable'\n",
    "    return _instr('ENV', f'{k}{'=%s' % v if v else ''}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d95a8e62b2f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _env('PATH', '/usr/local/bin') == 'ENV PATH=/usr/local/bin'\n",
    "assert _env('DEBIAN_FRONTEND=noninteractive') == 'ENV DEBIAN_FRONTEND=noninteractive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83047e4ca88feace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _expose(port):\n",
    "    'EXPOSE instruction -- declare container port'\n",
    "    return _instr('EXPOSE', str(port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5444ddf4942ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _expose(8080) == 'EXPOSE 8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c728427144919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _entrypoint(cmd):\n",
    "    'ENTRYPOINT instruction -- container entrypoint'\n",
    "    return _instr('ENTRYPOINT', json.dumps(cmd) if is_listy(cmd) else cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c31e379dddc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _entrypoint(['python', '-m', 'flask']) == 'ENTRYPOINT [\"python\", \"-m\", \"flask\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50bfa8ecc6627f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _arg(nm, def_=None):\n",
    "    'ARG instruction -- build-time variable'\n",
    "    return _instr('ARG', f'{nm}{'=%s' % def_ if def_ else ''}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67fd27a0dcae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _arg('VERSION', '1.0') == 'ARG VERSION=1.0'\n",
    "assert _arg('VERSION') == 'ARG VERSION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c6ddb6ffca82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _label(**kw):\n",
    "    'LABEL instruction -- image metadata'\n",
    "    return _instr('LABEL', joins(' ', (f'{k}=\"{v}\"' for k, v in kw.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93910bc0dcde2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _label(version='1.0', maintainer='me') == 'LABEL version=\"1.0\" maintainer=\"me\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f1a3ff26af0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _user(u):\n",
    "    'USER instruction -- set runtime user'\n",
    "    return _instr('USER', u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e15d4c987c26cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _volume(path):\n",
    "    'VOLUME instruction -- declare mount point'\n",
    "    return _instr('VOLUME', json.dumps(path) if is_listy(path) else path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7077d48d69ed42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _volume('/data') == 'VOLUME /data'\n",
    "assert _volume(['/data', '/logs']) == 'VOLUME [\"/data\", \"/logs\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ef358273c8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _shell(cmd):\n",
    "    'SHELL instruction -- override default shell'\n",
    "    return _instr('SHELL', json.dumps(cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a4943affad6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _shell(['/bin/bash', '-c']) == 'SHELL [\"/bin/bash\", \"-c\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c4e02a7981ea",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef _healthcheck(cmd, i=None, t=None, r=None, sp=None):\n    'HEALTHCHECK instruction -- container health check'\n    o2s = lambda k, v: f'--{k}={v}' if v else ''\n    o = ' '.join(filter(None, [o2s('interval',i), o2s('timeout',t), o2s('retries', r), o2s('start-period', sp)]))\n    c = json.dumps(cmd) if is_listy(cmd) else cmd\n    return _instr('HEALTHCHECK', f'{o} CMD {c}'.strip())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bbc29bc9f3843",
   "metadata": {},
   "outputs": [],
   "source": "assert 'CMD curl' in _healthcheck('curl -f http://localhost/', i='30s')\nassert _healthcheck('curl localhost', i='30s', t='10s') == 'HEALTHCHECK --interval=30s --timeout=10s CMD curl localhost'\nassert _healthcheck('curl localhost') == 'HEALTHCHECK CMD curl localhost'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824ecd74f59baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _stop_sig_(sig):\n",
    "    'STOPSIGNAL instruction -- set stop signal'\n",
    "    return _instr('STOPSIGNAL', sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa905903a7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _on_build(ins):\n",
    "    'ONBUILD instruction -- trigger for downstream builds'\n",
    "    return _instr('ONBUILD', str(ins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e798cacfb59393",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _on_build(_run('echo triggered')) == 'ONBUILD RUN echo triggered'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5f0eeeaca9c1d6",
   "metadata": {},
   "source": [
    "## Dockerfile Builder\n",
    "\n",
    "The `Dockerfile` class provides a fluent interface for building Dockerfiles. Start with a base image, chain instruction methods, then render or save.\n",
    "\n",
    "Each method is one line -- it creates an instruction and appends it, returning `self` for chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ja7m700to",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _parse(path_or_str: Path | str):\n",
    "    'Parse Dockerfile text into list of instruction strings'\n",
    "    t = Path(path_or_str).read_text() if isinstance(path_or_str, Path) else path_or_str\n",
    "    return L.splitlines(re.sub(r'\\\\\\n\\s*', '', t)).filter(lambda l: l.strip() and not l.strip().startswith('#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8wkmtg7oal",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = _parse(\"# comment\\nFROM python:3.11\\nRUN apt-get update && \\\\\\n    apt-get install -y curl\\nCOPY . /app\")\n",
    "print(parsed)\n",
    "assert len(parsed) == 3\n",
    "assert parsed[0] == 'FROM python:3.11'\n",
    "assert 'apt-get install -y curl' in parsed[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77afa11b44a44293",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nclass Dockerfile(L):\n    'Fluent builder for Dockerfiles'\n    def _new(self, items, **kw): return type(self)(items, use_list=None, **kw)\n    @classmethod\n    def load(cls, path:Path=Path('Dockerfile')): return cls(_parse(Path(path)))\n    def from_(self, base, tag=None, as_=None): return self._add(_from(base, tag, as_))\n    def _add(self, i): return self._new(self.items + [i])\n    def run(self, cmd): return self._add(_run(cmd))\n    def cmd(self, cmd): return self._add(_cmd(cmd))\n    def copy(self, src, dst, from_=None, link=False): return self._add(_copy(src, dst, from_, link))\n    def add(self, src, dst): return self._add(_add(src, dst))\n    def workdir(self, path='/app'): return self._add(_workdir(path))\n    def env(self, key, value=None): return self._add(_env(key, value))\n    def expose(self, port): return self._add(_expose(port))\n    def entrypoint(self, cmd): return self._add(_entrypoint(cmd))\n    def arg(self, name, default=None): return self._add(_arg(name, default))\n    def label(self, **kwargs): return self._add(_label(**kwargs))\n    def user(self, user): return self._add(_user(user))\n    def volume(self, path): return self._add(_volume(path))\n    def shell(self, cmd): return self._add(_shell(cmd))\n    def healthcheck(self, cmd, **kw): return self._add(_healthcheck(cmd, **kw))\n    def stopsignal(self, signal): return self._add(_stop_sig_(signal))\n    def onbuild(self, instruction): return self._add(_on_build(instruction))\n    def apt_install(self, *pkgs, y=False): return self._add(_apt_install(*pkgs, y=y))\n    def __call__(self, kw, *args, **kwargs):\n        'Build a generic Dockerfile instruction: kw ARG1 ARG2 --flag=val --bool-flag'\n        flags = [f'--{k.rstrip(\"_\").replace(\"_\",\"-\")}={v}' for k,v in kwargs.items() if v not in (True, False, None)]\n        flags += [f'--{k.rstrip(\"_\").replace(\"_\",\"-\")}' for k,v in kwargs.items() if v is True]\n        return self._add(f'{kw} {\" \".join([*flags, *[str(a) for a in args]])}')\n    def __getattr__(self, nm):\n        'Dispatch unknown instruction names: df.some_instr(arg) → SOME-INSTR arg'\n        if nm.startswith('_'): raise AttributeError(nm)\n        return partial(self, nm.upper().rstrip('_'))\n    def __str__(self): return chr(10).join(self)\n    def __repr__(self): return str(self)\n    def save(self, path:Path=Path('Dockerfile')):\n        Path(path).mk_write(str(self))\n        return path"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e0df1bab69e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (Dockerfile().from_('python:3.11-slim')\n",
    "    .run('pip install flask')\n",
    "    .copy('.', '/app')\n",
    "    .workdir('/app')\n",
    "    .expose(5000)\n",
    "    .cmd(['python', 'app.py']))\n",
    "\n",
    "expected = \"\"\"FROM python:3.11-slim\n",
    "RUN pip install flask\n",
    "COPY . /app\n",
    "WORKDIR /app\n",
    "EXPOSE 5000\n",
    "CMD [\\\"python\\\", \\\"app.py\\\"]\"\"\"\n",
    "\n",
    "assert str(df) == expected\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b3dc5e6c1d01e",
   "metadata": {},
   "source": [
    "Multi-stage builds work naturally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7511aca89b9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (Dockerfile().from_('golang:1.21', as_='builder')\n",
    "    .workdir('/src')\n",
    "    .copy('.', '.')\n",
    "    .run('go build -o /app')\n",
    "    .from_('alpine')\n",
    "    .copy('/app', '/app', from_='builder')\n",
    "    .cmd(['/app']))\n",
    "\n",
    "assert 'FROM golang:1.21 AS builder' in str(df)\n",
    "assert 'COPY --from=builder /app /app' in str(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f94268ab3813a3",
   "metadata": {},
   "source": [
    "Multi-command RUN chains with `&&`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1e299a337e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (Dockerfile().from_('ubuntu:22.04').run(['apt-get update', 'apt-get install -y python3', 'rm -rf /var/lib/apt/lists/*']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762bewtb215",
   "metadata": {},
   "source": [
    "### Loading from an existing Dockerfile\n",
    "\n",
    "Use `Dockerfile.load()` to read an existing Dockerfile. `save()` returns the `Path` it wrote to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0iv1dd9nzs7v",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "tmp = tempfile.mkdtemp()\n",
    "Path(f'{tmp}/Dockerfile').write_text(\"# My app\\nFROM python:3.11-slim\\nRUN apt-get update && \\\\\\n    apt-get install -y curl\\nCOPY . /app\\nCMD [\\\"python\\\", \\\"app.py\\\"]\")\n",
    "\n",
    "# Load existing Dockerfile\n",
    "df = Dockerfile.load(f'{tmp}/Dockerfile')\n",
    "assert len(df) == 4\n",
    "assert df[0] == 'FROM python:3.11-slim'\n",
    "\n",
    "# save returns the path and writes the file\n",
    "p = df.save(f'{tmp}/Dockerfile')\n",
    "assert Path(p).exists()\n",
    "\n",
    "# chain after loading\n",
    "df2 = df.run('echo hi')\n",
    "assert len(df2) == 5\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55a61eecbf7183",
   "metadata": {},
   "source": [
    "## Build, Run, Test\n",
    "\n",
    "These top-level functions wrap the Docker CLI for the common workflow: build an image from a `Dockerfile`, run a container, and test that a command succeeds inside an image.\n",
    "\n",
    "### Requires Docker daemon\n",
    "\n",
    "The functions below need a running Docker daemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe618740a1c539",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef _clean_cfg():\n    'Create a docker config dir with credential helpers stripped'\n    src = Path(os.environ.get('DOCKER_CONFIG', Path.home()/'.docker'))\n    dst = Path.home()/'.dockr'/'config'\n    cfgf = dst/'config.json'\n    if cfgf.exists(): return str(dst)\n    cfg = src.joinpath('config.json').read_json() if (src/'config.json').exists() else {}\n    cfg.pop('credsStore', None); cfg.pop('credHelpers', None)\n    cfgf.write_json(cfg)\n    ctx_src, ctx_dst = src/'contexts', dst/'contexts'\n    if ctx_src.exists() and not ctx_dst.exists(): ctx_dst.symlink_to(ctx_src)\n    return str(dst)\n\ndef calldocker(*args, no_creds=False):\n    'Run a docker CLI command, return stdout. Respects DOCKR_RUNTIME env var (default: docker).'\n    rt = os.environ.get('DOCKR_RUNTIME', 'docker')\n    pre = ('--config', _clean_cfg()) if no_creds and rt == 'docker' else ()\n    return subprocess.run((rt,) + pre + args, capture_output=True, text=True, check=True).stdout.strip()\n\nclass Docker:\n    'Wrap docker CLI: __getattr__ dispatches subcommands, kwargs become flags'\n    def __init__(self, no_creds=False): self.no_creds = no_creds\n\n    def __call__(self, cmd, *args, **kwargs):\n        fargs = list(args)\n        fargs += concat([f'-{k}', str(v)] for k,v in kwargs.items() if len(k)==1 and v not in (True, False, None))\n        fargs += [f'-{k}' for k,v in kwargs.items() if len(k)==1 and v is True]\n        fargs += [f'--{k.rstrip(\"_\").replace(\"_\",\"-\")}={v}' for k,v in kwargs.items() if len(k)>1 and v not in (True, False, None)]\n        fargs += [f'--{k.rstrip(\"_\").replace(\"_\",\"-\")}' for k,v in kwargs.items() if len(k)>1 and v is True]\n        return calldocker(cmd, *fargs, no_creds=self.no_creds)\n\n    def __getattr__(self, nm):\n        if nm.startswith('_'): raise AttributeError(nm)\n        return partial(self, nm.replace('_', '-'))\n\ndk = Docker()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10280a7aae03af",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef build(df:Dockerfile, tag:str=None, path:str='.', rm=True, no_creds=False):\n    'Build image from Dockerfile. path is the build context directory.'\n    df.save(Path(path) / 'Dockerfile')\n    Docker(no_creds=no_creds).build(str(path), t=tag, rm=rm)\n    return tag"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e35aaa6ab2848",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef test(img_or_tag:str, cmd):\n    'Run cmd in image, return True if exit code 0'\n    try: dk.run('--rm', str(img_or_tag), *listify(cmd)); return True\n    except Exception: return False"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d50c77e24ddc9",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef run(img_or_tag:str, detach=False, ports=None, name=None, remove=False, command=None):\n    'Run a container, return container ID (detached) or output'\n    args = []\n    if detach: args.append('-d')\n    if remove: args.append('--rm')\n    if name: args += ['--name', name]\n    for cp, hp in (ports or {}).items(): args += ['-p', f'{hp}:{cp.split(\"/\")[0]}']\n    return dk('run', *args, str(img_or_tag), *listify(command or []))"
  },
  {
   "cell_type": "markdown",
   "id": "1112ac96c3fdb6d7",
   "metadata": {},
   "source": [
    "### Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa9e9480de4c3f",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef containers(all=False):\n    'List running containers (names)'\n    return dk.ps(format='{{.Names}}', a=all).splitlines()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4cd5b26a74b9d",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef images():\n    'List image tags'\n    return dk.images(format='{{.Repository}}:{{.Tag}}').splitlines()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f07d40d17a92c",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef stop(name_or_id:str):\n    'Stop a container by name or ID'\n    dk.stop(name_or_id)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937eef6de6b03491",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef logs(name_or_id:str, n=10):\n    'Tail logs of a container'\n    return dk.logs(name_or_id, tail=n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jjdj9t1tjhl",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef rm(name_or_id:str, force=False):\n    'Remove a container by name or ID'\n    dk.rm(name_or_id, f=force)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vm8xmxstny",
   "metadata": {},
   "outputs": [],
   "source": "#| export\ndef rmi(image:str, force=False):\n    'Remove an image by name or ID'\n    dk.rmi(image, f=force)"
  },
  {
   "cell_type": "markdown",
   "id": "3n6ekh4wnfl",
   "metadata": {},
   "source": [
    "### Example: FastHTML app with uv\n",
    "\n",
    "A realistic Dockerfile for a [FastHTML](https://fastht.ml) app that uses `uv` for dependency management, installs system packages, and is designed to run with a mounted volume for persistent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dqbwny13yr",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (Dockerfile().from_('python', '3.12-slim')\n",
    "    .apt_install('curl', 'sqlite3', y=True)\n",
    "    .run('pip install uv')\n",
    "    .workdir('/app')\n",
    "    .copy('pyproject.toml', '.')\n",
    "    .run('uv export --no-hashes -o requirements.txt && pip install -r requirements.txt')\n",
    "    .copy('.', '.')\n",
    "    .volume('/app/data')\n",
    "    .expose(5001)\n",
    "    .cmd(['python', 'main.py']))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfcde6c13da345",
   "metadata": {},
   "outputs": [],
   "source": "import tempfile\ntmp = tempfile.mkdtemp()\n\ndf = Dockerfile().from_('alpine').run('echo hello > /greeting.txt').cmd(['cat', '/greeting.txt'])\ntry:\n    tag = df.build(tag='dockr-test:hello', path=tmp, no_creds=True)\n    print(f'Built: {tag}')\n    out = run(tag, remove=True)\n    print(f'Output: {out}')\n    rmi(tag)\n    print('Cleaned up.')\nexcept Exception as e: print(f'Docker not available: {e}')"
  },
  {
   "cell_type": "markdown",
   "id": "3cfb3be5",
   "metadata": {},
   "source": [
    "### End-to-end: FastHTML + FastLite todo app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e135ff",
   "metadata": {},
   "outputs": [],
   "source": "import tempfile, os\napp_dir = Path(tempfile.mkdtemp()) / 'fasthtml-todo'\napp_dir.mkdir()\n\n# --- main.py: FastHTML + FastLite todo app ---\n(app_dir / 'main.py').write_text('''import json as jsonlib\nfrom fasthtml.common import *\n\ndb = database('data/todos.db')\ntodos = db.t.todos\nif todos not in db.t: todos.create(id=int, title=str, done=bool, pk='id')\nTodo = todos.dataclass()\n\napp, rt = fast_app(live=False)\n\n@rt('/')\ndef get():\n    items = [Li(f\"{'✓' if t.done else '○'} {t.title}\", id=f'todo-{t.id}') for t in todos()]\n    return Titled('Todos',\n        Ul(*items),\n        Form(Input(name='title', placeholder='New todo...'), Button('Add'), action='/add', method='post'))\n\n@rt('/add', methods=['post'])\ndef post(title: str):\n    todos.insert(Todo(title=title, done=False))\n    return Redirect('/')\n\n@rt('/api/todos')\ndef api():\n    data = [dict(id=t.id, title=t.title, done=t.done) for t in todos()]\n    return Response(jsonlib.dumps(data), media_type='application/json')\n\nserve(host='0.0.0.0', port=5001)\n''')\n\n# --- requirements.txt ---\n(app_dir / 'requirements.txt').write_text('python-fasthtml\\n')\n\nprint(f'App dir: {app_dir}')\nprint('Files:', os.listdir(app_dir))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (Dockerfile()\n",
    "    .from_('python', '3.12-slim')\n",
    "    .workdir('/app')\n",
    "    .copy('requirements.txt', '.')\n",
    "    .run('pip install --no-cache-dir -r requirements.txt')\n",
    "    .copy('.', '.')\n",
    "    .volume('/app/data')\n",
    "    .expose(5001)\n",
    "    .cmd(['python', 'main.py']))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad11d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from fastcore.net import urlread, urljson\n",
    "\n",
    "tag = 'dockr-fasthtml:latest'\n",
    "name = 'dockr-fasthtml-demo'\n",
    "try:\n",
    "    df.build(tag=tag, path=str(app_dir), no_creds=True)\n",
    "    print(f'Built: {tag}')\n",
    "    try: rm(name, force=True)\n",
    "    except: pass\n",
    "    cid = run(tag, detach=True, ports={'5001/tcp': 5001}, name=name)\n",
    "    print(f'Container: {cid[:12]}')\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Add some todos via POST\n",
    "    url = 'http://localhost:5001'\n",
    "    for t in ['Buy milk', 'Write docs', 'Ship dockr']: urlread(f'{url}/add', title=t)\n",
    "    # Fetch the JSON API\n",
    "    for t in urljson(f'{url}/api/todos'): print(f\"  {'✓' if t['done'] else '○'} {t['title']}\")\n",
    "    print(f'\\nLogs:')\n",
    "    print(logs(name, n=3))\n",
    "except IOError as e: print(f'Docker not available: {e}')\n",
    "finally:\n",
    "    try: rm(name, force=True)\n",
    "    except: pass\n",
    "    try: rmi(tag)\n",
    "    except: pass\n",
    "    print('Cleaned up.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5e914c8b3fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
